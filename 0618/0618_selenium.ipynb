{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"634aad6e4ab24a6092741e0ac66883ec\")>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome('chromedriver_90')\n",
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://ldjwj.github.io/00_SBA01_BigData/05_HTML/idx_lec_list'\n",
    "driver.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_link1=driver.find_element_by_xpath('/html/body/div/div/div/div/div[7]/div[4]/a')\n",
    "sel_link1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.chrome.webdriver.WebDriver (session=\"177948922b9dc97efe5838f3e91f852e\")>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "driver=webdriver.Chrome('chromedriver_90')\n",
    "driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://ldjwj.github.io/00_SBA01_BigData/05_HTML/idx_lec_list'\n",
    "driver.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_link2=driver.find_elements_by_class_name(\"row\")\n",
    "sel_link2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_element_by_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pythonstart.github.io/web/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10. 랭킹 정보 가져오기(웹 크롤링)\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "sel_id=driver.find_element_by_id('rank')\n",
    "print(sel_id.text)\n",
    "print(sel_id.tag_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_elements_by_tag_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 01. 제목 가져오기(title)\n",
      "a 02. 텍스트 가져오기(p)\n",
      "a 03. 링크 가져오기(a)\n",
      "a 04. 이미지 정보 가져오기(img)\n",
      "a 05. 리스트 정보 가져오기(ul,ol)\n",
      "a 06. id를 활용한 정보 획득\n",
      "a 07. class를 활용한 정보 획득\n",
      "a 08. 하나의 이미지 다운로드\n",
      "a 09. 여러개의 이미지 다운로드\n",
      "a 10. 랭킹 정보 가져오기(웹 크롤링)\n"
     ]
    }
   ],
   "source": [
    "sel_a_all=driver.find_elements_by_tag_name('a')\n",
    "\n",
    "for one in sel_a_all:\n",
    "    print(one.tag_name,one.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_element_by_link_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 01. 제목 가져오기(title)\n"
     ]
    }
   ],
   "source": [
    "sel_link = driver.find_element_by_link_text(\"01. 제목 가져오기(title)\")\n",
    "print(sel_link.tag_name, sel_link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_element_by_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 01. 제목 가져오기(title)\n",
      "a 03. 링크 가져오기(a)\n"
     ]
    }
   ],
   "source": [
    "`sel_name=driver.find_elements_by_name('link_get')\n",
    "for i in sel_name:\n",
    "    print(i.tag_name, i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_elements_by_css_selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 01. 제목 가져오기(title)\n",
      "a 02. 텍스트 가져오기(p)\n",
      "a 03. 링크 가져오기(a)\n",
      "a 04. 이미지 정보 가져오기(img)\n",
      "a 05. 리스트 정보 가져오기(ul,ol)\n",
      "a 06. id를 활용한 정보 획득\n",
      "a 07. class를 활용한 정보 획득\n",
      "a 08. 하나의 이미지 다운로드\n",
      "a 09. 여러개의 이미지 다운로드\n",
      "a 10. 랭킹 정보 가져오기(웹 크롤링)\n"
     ]
    }
   ],
   "source": [
    "sel_css=driver.find_elements_by_css_selector('body ul a')\n",
    "\n",
    "for one in sel_css:\n",
    "    print(one.tag_name, one.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_elements_by_partial_link_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a 01. 제목 가져오기(title)\n",
      "a 02. 텍스트 가져오기(p)\n",
      "a 03. 링크 가져오기(a)\n",
      "a 04. 이미지 정보 가져오기(img)\n",
      "a 05. 리스트 정보 가져오기(ul,ol)\n",
      "a 10. 랭킹 정보 가져오기(웹 크롤링)\n"
     ]
    }
   ],
   "source": [
    "sel_p_link=driver.find_elements_by_partial_link_text('가져오기')\n",
    "\n",
    "for one in sel_p_link:\n",
    "    print(one.tag_name, one.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-3 실습 - 아래 링크의 Content 내용을 가져와 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://ldjwj.github.io/00_SBA01_BigData/05_HTML/idx_lec_list'\n",
    "driver.get(url) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content\n",
      "R 기본 전체(전 수업 링크)\n",
      "통계기본이해하기(1)\n",
      "가설검정이해(1)\n",
      "통계기본이해_실습(1)-통계가설검정\n",
      "통계기본이해_실습(1)-통계가설검정\n",
      "회귀분석이해(1)\n",
      "첫번째 모델 만들기\n",
      "회귀 모델 실습(1)-mtcars\n",
      "회귀 모델 실습(2)-Boston 집값 예측\n",
      "회귀 모델 실습(3) - 캐글 데이터-집값 예측\n",
      "로지스틱 회귀 모델 실습(1) - 인디언 암 예측\n",
      "의사결정트리 기본 이해(1)\n",
      "의사결정트리 실습(1)\n",
      "의사결정트리 실습(2)\n",
      "데이터 탐색 - Boston 집값\n",
      "텍스트 마이닝 시작하기\n",
      "KoNLP를 패키지를 활용한 텍스트 분석(1)\n",
      "텍스트 감정 분석(1)\n",
      "TFIDF 이해하기(1)\n",
      "R과 MySQL 연동 환경 만들기\n",
      "R과 MySQL 연동 실습하기\n",
      "데이터 시각화 기본(1)\n",
      "데이터 시각화 기본(2)\n",
      "데이터 시각화 기본(3)\n",
      "데이터 시각화 기본(4)\n",
      "데이터 시각화 활용(5)\n",
      "데이터 시각화 참고자료(1)\n",
      "데이터 시각화 참고자료(2)\n"
     ]
    }
   ],
   "source": [
    "sel_link5 = driver.find_elements_by_xpath('/html/body/div/div/div/div/div/div[3]')\n",
    "for i in sel_link5:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-3 실습2 - 아래 링크의 Content내용과 Link의 URL을 가져와보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R 기본 전체(전 수업 링크)\n",
      "https://github.com/LDJWJ/RBasic/tree/master/01_RClass\n",
      "통계기본이해하기(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/Stat01_01_Basic_Summary_v12.pdf\n",
      "가설검정이해(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/Stat01_02_Hypo_v10.pdf\n",
      "통계기본이해_실습(1)-통계가설검정\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat01_Lab02_ttest_v11.html\n",
      "통계기본이해_실습(1)-통계가설검정\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat01_Lab02_v10.html\n",
      "회귀분석이해(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/Stat02_Regression_v10.pdf\n",
      "첫번째 모델 만들기\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab01_lm_firstmodel.html\n",
      "회귀 모델 실습(1)-mtcars\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab02_lm_mtcars.html\n",
      "회귀 모델 실습(2)-Boston 집값 예측\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab03_lm_housing.html\n",
      "회귀 모델 실습(3) - 캐글 데이터-집값 예측\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab04_lm_house_adv.html\n",
      "로지스틱 회귀 모델 실습(1) - 인디언 암 예측\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat03_Lab05_logit_indian.html\n",
      "의사결정트리 기본 이해(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat04_decisiontree_v11.pdf\n",
      "의사결정트리 실습(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat04_Lab01_tree_titanic.html\n",
      "의사결정트리 실습(2)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat04_Lab02_tree_titanic.html\n",
      "데이터 탐색 - Boston 집값\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab03_eda_housing.html\n",
      "텍스트 마이닝 시작하기\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/R_LV_Up08_TextMining.html\n",
      "KoNLP를 패키지를 활용한 텍스트 분석(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/TM_Lab01_KoNLP.html\n",
      "텍스트 감정 분석(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/TM_LAB06_sentiment.html\n",
      "TFIDF 이해하기(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/TM_Lab02_tfidf01.html\n",
      "R과 MySQL 연동 환경 만들기\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/R_MYSQL_01_1909.pdf\n",
      "R과 MySQL 연동 실습하기\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/R_LV_Up_MySQL01.html\n",
      "데이터 시각화 기본(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B01_dataVis0418.pdf\n",
      "데이터 시각화 기본(2)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B01_plot_basic.pdf\n",
      "데이터 시각화 기본(3)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B02_ggplot2_jitter.pdf\n",
      "데이터 시각화 기본(4)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B03_ggplot2_custom.pdf\n",
      "데이터 시각화 활용(5)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/DataVis_R_Lab07_networkAna01.r\n",
      "데이터 시각화 참고자료(1)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/G01_Graph_0601.r\n",
      "데이터 시각화 참고자료(2)\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/G02_Graph_0601.r\n"
     ]
    }
   ],
   "source": [
    "sel_link3 = driver.find_elements_by_xpath('/html/body/div/div/div/div/div/div[4]/a')\n",
    "for i in range(len(sel_link3)):\n",
    "    print(sel_link5[i+1].text)\n",
    "    print(sel_link3[i].get_attribute(\"href\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://github.com/LDJWJ/RBasic/tree/master/01_RClass\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/Stat01_01_Basic_Summary_v12.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/Stat01_02_Hypo_v10.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat01_Lab02_ttest_v11.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat01_Lab02_v10.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/Stat02_Regression_v10.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab01_lm_firstmodel.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab02_lm_mtcars.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab03_lm_housing.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab04_lm_house_adv.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat03_Lab05_logit_indian.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat04_decisiontree_v11.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat04_Lab01_tree_titanic.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat04_Lab02_tree_titanic.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/stat02_Lab03_eda_housing.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/R_LV_Up08_TextMining.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/TM_Lab01_KoNLP.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/TM_LAB06_sentiment.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/TM_Lab02_tfidf01.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/R_MYSQL_01_1909.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/R_LV_Up_MySQL01.html\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B01_dataVis0418.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B01_plot_basic.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B02_ggplot2_jitter.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/B03_ggplot2_custom.pdf\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/DataVis_R_Lab07_networkAna01.r\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/G01_Graph_0601.r\n",
      "https://ldjwj.github.io/00_SBA01_BigData/05_HTML/01_RClass/G02_Graph_0601.r\n",
      "https://colorlib.com/wp/template/responsive-table-v2/\n"
     ]
    }
   ],
   "source": [
    "sel_link6 = driver.find_elements_by_xpath('//a[@href]')\n",
    "for i in sel_link6:\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5-4 (추가)실습 - 아래 링크의 전체 내용을 가져와 이를 엑셀로 정리해 보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.selenium웹페이지를 띄우고\n",
    "2.해당 웹의 html소스를 얻어오자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>나의 웹 페이지</title>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page=driver.page_source\n",
    "soup=BeautifulSoup(page,'lxml')\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-1 실습1. BeautifulSoup를 이용해서 전체 링크 내용을 가져와 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"./01.html\" name=\"link_get\" target=\"_blank\"> 01. 제목 가져오기(title) </a>,\n",
       " <a href=\"./02.html\" name=\"text_get\" target=\"_blank\"> 02. 텍스트 가져오기(p) </a>,\n",
       " <a href=\"./03.html\" name=\"link_get\" target=\"_blank\"> 03. 링크 가져오기(a) </a>,\n",
       " <a href=\"https://pythonstart.github.io/web/04.html\" target=\"_blank\"> 04. 이미지 정보 가져오기(img) </a>,\n",
       " <a href=\"./05.html\" target=\"_blank\"> 05. 리스트 정보 가져오기(ul,ol) </a>,\n",
       " <a href=\"./06.html\" target=\"_blank\"> 06. id를 활용한 정보 획득 </a>,\n",
       " <a href=\"./07.html\" target=\"_blank\"> 07. class를 활용한 정보 획득 </a>,\n",
       " <a href=\"./08.html\" target=\"_blank\"> 08. 하나의 이미지 다운로드 </a>,\n",
       " <a href=\"https://pythonstart.github.io/web/09.html\" target=\"_blank\"> 09. 여러개의 이미지 다운로드 </a>,\n",
       " <a href=\"./10.html\" id=\"rank\" target=\"_blank\"> 10. 랭킹 정보 가져오기(웹 크롤링) </a>]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=soup.find_all('a')\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 01. 제목 가져오기(title) \n",
      " 02. 텍스트 가져오기(p) \n",
      " 03. 링크 가져오기(a) \n",
      " 04. 이미지 정보 가져오기(img) \n",
      " 05. 리스트 정보 가져오기(ul,ol) \n",
      " 06. id를 활용한 정보 획득 \n",
      " 07. class를 활용한 정보 획득 \n",
      " 08. 하나의 이미지 다운로드 \n",
      " 09. 여러개의 이미지 다운로드 \n",
      " 10. 랭킹 정보 가져오기(웹 크롤링) \n"
     ]
    }
   ],
   "source": [
    "a=soup.find_all('a')\n",
    "for one in a:\n",
    "    print(one.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-2 실습2. Selenium를 이용(함수 find_elements...)을 이용해서 전체 링크를 가져와 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01. 제목 가져오기(title)\n",
      "02. 텍스트 가져오기(p)\n",
      "03. 링크 가져오기(a)\n",
      "04. 이미지 정보 가져오기(img)\n",
      "05. 리스트 정보 가져오기(ul,ol)\n",
      "06. id를 활용한 정보 획득\n",
      "07. class를 활용한 정보 획득\n",
      "08. 하나의 이미지 다운로드\n",
      "09. 여러개의 이미지 다운로드\n",
      "10. 랭킹 정보 가져오기(웹 크롤링)\n"
     ]
    }
   ],
   "source": [
    "all_link1 = driver.find_elements_by_xpath('/html/body/ul/a')\n",
    "for i in all_link1:\n",
    "    print(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://pythonstart.github.io/web/01.html\n",
      "https://pythonstart.github.io/web/02.html\n",
      "https://pythonstart.github.io/web/03.html\n",
      "https://pythonstart.github.io/web/04.html\n",
      "https://pythonstart.github.io/web/05.html\n",
      "https://pythonstart.github.io/web/06.html\n",
      "https://pythonstart.github.io/web/07.html\n",
      "https://pythonstart.github.io/web/08.html\n",
      "https://pythonstart.github.io/web/09.html\n",
      "https://pythonstart.github.io/web/10.html\n"
     ]
    }
   ],
   "source": [
    "all_link2 = driver.find_elements_by_xpath('//a[@href]')\n",
    "for i in all_link2:\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6-2 (추가) 02. 텍스트 가져오기, 03. 링크 가져오기 페이지의 내용을 가지고 오기."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여기는 두번째 단계\n",
      "01 시작이 반이다\n",
      "02 포기하지말고 화이팅!\n",
      "03 응원합니다.\n",
      "\n",
      "네이버 : https://www.naver.com/\n",
      "구글 : https://www.google.co.kr/\n",
      "마이크로 소프트 : https://www.microsoft.com/ko-kr\n",
      "카카오 : https://www.kakaocorp.com/\n"
     ]
    }
   ],
   "source": [
    "url_1 = 'https://pythonstart.github.io/web/02.html'\n",
    "url_2 = 'https://pythonstart.github.io/web/03.html'\n",
    "\n",
    "driver.get(url_1)\n",
    "list_2 = driver.find_elements_by_tag_name('p')\n",
    "for one in list_2:\n",
    "    print(one.text)\n",
    "print()\n",
    "\n",
    "driver.get(url_2)\n",
    "list_3 = driver.find_elements_by_xpath('//a[@href]')\n",
    "for two in list_3:\n",
    "    print(two.text, ':', two.get_attribute('href'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
