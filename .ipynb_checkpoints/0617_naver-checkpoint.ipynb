{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "html= \"\"\"\n",
    "<html>\n",
    "<head><title> test site </title></head>\n",
    "<p class='class1' align=\"left\">test3</p>\n",
    "<p class='class1'>test2</p>\n",
    "<p id='p1'>오늘의 주가지수 1500</p>\n",
    "<span class='class3'>span tag text</span>\n",
    "<p class='class4'>test3</p>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= BeautifulSoup(html, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   test site\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p align=\"left\" class=\"class1\">\n",
      "   test3\n",
      "  </p>\n",
      "  <p class=\"class1\">\n",
      "   test2\n",
      "  </p>\n",
      "  <p id=\"p1\">\n",
      "   오늘의 주가지수 1500\n",
      "  </p>\n",
      "  <span class=\"class3\">\n",
      "   span tag text\n",
      "  </span>\n",
      "  <p class=\"class4\">\n",
      "   test3\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( soup.prettify() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<html>\n",
       " <head><title> test site </title></head>\n",
       " <body><p align=\"left\" class=\"class1\">test3</p>\n",
       " <p class=\"class1\">test2</p>\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>\n",
       " <span class=\"class3\">span tag text</span>\n",
       " <p class=\"class4\">test3</p>\n",
       " </body></html>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<p align=\"left\" class=\"class1\">test3</p>,\n",
       " '\\n',\n",
       " <p class=\"class1\">test2</p>,\n",
       " '\\n',\n",
       " <p id=\"p1\">오늘의 주가지수 1500</p>,\n",
       " '\\n',\n",
       " <span class=\"class3\">span tag text</span>,\n",
       " '\\n',\n",
       " <p class=\"class4\">test3</p>,\n",
       " '\\n']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(soup.body.children) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after'\n",
    "basic_url = \"https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after&page=\"\n",
    "# 2page \n",
    "# 3page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a코드로 코멘트 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" '이게 진짜 현대예술이지'\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = \"https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after&page=1\"\n",
    "page = urlopen(url1)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "comment_all = soup.find_all('td', class_='title')\n",
    "comment=comment_all[9].find_all('a')[1]\n",
    "comment.get(\"onclick\").split(',')[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(comment_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이게 진짜 현대예술이지'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_all[9].find(\"br\").next_sibling.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'이게 진짜 현대예술이지'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=list(comment_all[9].children)\n",
    "a[6].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-2 실습확인 -  1페이지 리뷰 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['곤니찌와에서 ㅡ ㅡ ... 재밌다가 식었음 ㅠ',\n",
       " '이게 예술이 아니면 뭔가요?',\n",
       " '와 ㄹㅇ 내 인생 영화에 들어갈정도로 재밌음. 특유의 BOOM이라던가 만화같은 연출이랑 팝송같은 음악이 너무 좋았음',\n",
       " '명대사:헤이',\n",
       " '진짜 고퀄리티다....',\n",
       " '스파이더맨 판권을 소니가 가져야 하는 이유',\n",
       " '갠적으로 영화 2번이상 보고싶은거 없었는데 생겼다. 힘든요즘 힘내게 해준영화 왜 이제봤지?',\n",
       " '영화도 재밌는데 연출이 일단 개신선하고 무엇보다 ost가 진짜 죽인다 ㅋㅋㅋㅋ',\n",
       " '영상미 색감 액션 정말 삼박자를 다갖춘 영화에요ㅜㅜㅜ 다채로운 색의 조합이 눈을 즐겁게 만들고 화려한액션은 정말 말할것도 없네요.... 극장에서 못본게 아쉽네요 정말 재밌게 봤습니다 !!',\n",
       " '이게 진짜 현대예술이지']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url1 = \"https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after&page=1\"\n",
    "page = urlopen(url1)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "comment_all = soup.find_all('td', class_='title')\n",
    "comments=[]\n",
    "for one in comment_all:\n",
    "    one_com=list(one.children)[6].strip()\n",
    "    comments.append(one_com)\n",
    "\n",
    "comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '곤니찌와에서 ㅡ ㅡ ... 재밌다가 식었음 ㅠ'\n",
      " '이게 예술이 아니면 뭔가요?'\n",
      " '와 ㄹㅇ 내 인생 영화에 들어갈정도로 재밌음. 특유의 BOOM이라던가 만화같은 연출이랑 팝송같은 음악이 너무 좋았음'\n",
      " '명대사:헤이'\n",
      " '진짜 고퀄리티다.... '\n",
      " '스파이더맨 판권을 소니가 가져야 하는 이유'\n",
      " '갠적으로 영화 2번이상 보고싶은거 없었는데 생겼다. 힘든요즘 힘내게 해준영화 왜 이제봤지?'\n",
      " '영화도 재밌는데 연출이 일단 개신선하고 무엇보다 ost가 진짜 죽인다 ㅋㅋㅋㅋ'\n",
      " '영상미 색감 액션 정말 삼박자를 다갖춘 영화에요ㅜㅜㅜ 다채로운 색의 조합이 눈을 즐겁게 만들고 화려한액션은 정말 말할것도 없네요.... 극장에서 못본게 아쉽네요 정말 재밌게 봤습니다 !!'\n",
      " '이게 진짜 현대예술이지'\n"
     ]
    }
   ],
   "source": [
    "url1 = \"https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after&page=1\"\n",
    "page = urlopen(url1)\n",
    "soup = BeautifulSoup(page, \"html.parser\")\n",
    "comment1_all = soup.find_all('td', class_='title')\n",
    "comment1=comment1_all[9].find_all('a')[1].get(\"onclick\").split(',')[2]\n",
    "\n",
    "for idx,comment in enumerate(comment1_all):\n",
    "    one_comment=comment.find_all('a')[1].get(\"onclick\").split(',')[2]\n",
    "    print(one_comment)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " '곤니찌와에서 ㅡ ㅡ ... 재밌다가 식었음 ㅠ'\n",
      " '이게 예술이 아니면 뭔가요?'\n",
      " '와 ㄹㅇ 내 인생 영화에 들어갈정도로 재밌음. 특유의 BOOM이라던가 만화같은 연출이랑 팝송같은 음악이 너무 좋았음'\n",
      " '명대사:헤이'\n",
      " '진짜 고퀄리티다.... '\n",
      " '스파이더맨 판권을 소니가 가져야 하는 이유'\n",
      " '갠적으로 영화 2번이상 보고싶은거 없었는데 생겼다. 힘든요즘 힘내게 해준영화 왜 이제봤지?'\n",
      " '영화도 재밌는데 연출이 일단 개신선하고 무엇보다 ost가 진짜 죽인다 ㅋㅋㅋㅋ'\n",
      " '영상미 색감 액션 정말 삼박자를 다갖춘 영화에요ㅜㅜㅜ 다채로운 색의 조합이 눈을 즐겁게 만들고 화려한액션은 정말 말할것도 없네요.... 극장에서 못본게 아쉽네요 정말 재밌게 봤습니다 !!'\n",
      " '이게 진짜 현대예술이지'\n"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after&page=1'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "sentence = soup.findAll('td', class_='title')\n",
    "for idx, comment in enumerate(sentence):\n",
    "    list_comment = comment.findAll('a')\n",
    "    print(list_comment[1].get('onclick').split(',')[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n"
     ]
    }
   ],
   "source": [
    "comments_allpage = []\n",
    "cnt = 0\n",
    "for i in range(1,8):\n",
    "    url = basic_url + str(i)\n",
    "    page = urlopen(url)\n",
    "    soup = BeautifulSoup(page, 'html.parser')\n",
    "    comment_all = soup.find_all('td', class_='title')\n",
    "    #comments = []\n",
    "    for one in comment_all:\n",
    "        one_com = list(one.children)[6].strip()\n",
    "        #comments.append(one_com)\n",
    "        comments_allpage.append(one_com)\n",
    "    time.sleep(3)\n",
    "    \n",
    "print(len(comments_allpage))\n",
    "# print(len(comments_allpage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints', '0617_naver.ipynb', 'D2Coding.ttf', '스파이더맨리뷰_0617.csv']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_doc={\"text\":comments_allpage}\n",
    "doc=pd.DataFrame(dict_doc)\n",
    "doc.to_csv(\"스파이더맨리뷰_0617.csv\",index=False)\n",
    "\n",
    "os.listdir(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-6188e92f1730>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'td'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mlist_comment\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfindAll\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'br'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_sibling\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_comment\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\bs4\\element.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2171\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2172\u001b[0m         \u001b[1;34m\"\"\"Raise a helpful exception to explain a common code fix.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2173\u001b[1;33m         raise AttributeError(\n\u001b[0m\u001b[0;32m   2174\u001b[0m             \u001b[1;34m\"ResultSet object has no attribute '%s'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2175\u001b[0m         )\n",
      "\u001b[1;31mAttributeError\u001b[0m: ResultSet object has no attribute 'find'. You're probably treating a list of elements like a single element. Did you call find_all() when you meant to call find()?"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "url = 'https://movie.naver.com/movie/point/af/list.nhn?st=mcode&sword=171725&target=after&page=1'\n",
    "page = urlopen(url)\n",
    "soup = BeautifulSoup(page, 'html.parser')\n",
    "sentence = soup.findAll('td', class_='title')\n",
    "for idx, comment in enumerate(sentence):\n",
    "    list_comment = comment.findAll('a').find('br').next_sibling.strip()\n",
    "    print(list_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"스파이더맨리뷰_0617.csv\", encoding=\"utf-8\")\n",
    "#f = open(\"SpiderMan.txt\", 'r', encoding='utf-8')\n",
    "text = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rc\n",
    "rc('font', family='NanumGothic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8a3b138312c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m wcloud = WordCloud('./data/D2Coding.ttf',\n\u001b[0;32m      2\u001b[0m                    \u001b[0mmax_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m                    relative_scaling = 0.2).generate(text)\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'text' is not defined"
     ]
    }
   ],
   "source": [
    "wcloud = WordCloud('./data/D2Coding.ttf',\n",
    "                   max_words=1000,\n",
    "                   relative_scaling = 0.2).generate(text)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
